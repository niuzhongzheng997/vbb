2. 识别计算任务中的性能瓶颈
这个功能的核心是关联业务逻辑（任务执行状态）与系统资源指标，进行根因分析。

实现计划：

a. 数据采集与关联

来源1：Aquila Trail（业务状态）

关键数据：Job ID、Task ID、任务状态（超时/失败/重试）、任务排队与开始/结束时间、任务总耗时。

来源2：云厂商原生监控服务（系统指标）

AWS CloudWatch / Azure Monitor：自动收集所有EC2实例（计算节点）的详细系统指标：

CPU利用率（CPUUtilization）

内存利用率（MemUsedPercent）

磁盘I/O（DiskReadBytes, DiskWriteBytes, EBSReadIOPS等）

网络I/O（NetworkIn, NetworkOut）

关键点：确保所有Aquila的计算实例都打上统一的资源标签（如 AquilaGrid: XVA-Batch），以便于筛选。

b. 数据分析与关联引擎

触发条件：系统定期扫描Trail，寻找状态为 “超时”、“执行时间异常长”（超过历史平均时间N个标准差）或 “失败/重试” 的任务。

关联分析：

当发现一个有问题任务（如 Job J123）时，从Trail中找出执行这个任务的具体计算实例（如 Instance i-abc123）以及任务的执行时间窗口（如 14:00 - 15:30）。

自动查询 CloudWatch，获取在该时间窗口内，实例 i-abc123 的CPU、内存、磁盘I/O、网络I/O等系统指标的时间序列数据。

瓶颈识别逻辑：

CPU瓶颈：在任务执行期间，CPU利用率持续高于90%。

内存瓶颈：可用内存持续过低，可能触发SWAP，导致磁盘I/O升高和性能骤降。

磁盘I/O瓶颈：磁盘读写队列深度持续很高或吞吐量达到极限。

网络瓶颈：网络吞吐量达到实例类型的极限。

资源竞争：同一个实例上运行多个Worker，它们竞争CPU、内存或网络资源。

c. 报告生成与反馈

自动生成诊断报告：为每个识别出的问题任务生成一份简要报告。

报告内容：

任务ID、用户、状态。

疑似瓶颈：如“高CPU利用率导致计算缓慢”。

证据：提供关键系统指标的截图或数据摘要（如“任务期间平均CPU利用率为98%”）。

优化建议：如“建议使用计算优化型实例（如C系列）而非内存优化型实例（如R系列）”。

用户通知：

将这份诊断报告通过邮件自动发送给任务提交者。

在Trail GUI中该任务的详情页面上，用一个明显的警告图标或标签（如 “性能瓶颈”）来展示这份报告，方便用户回溯和查询。
这部分也给我翻译一个英文版

Of course. Here is the English translation of the performance bottleneck identification plan.

 2. Identification of Performance Bottlenecks in Computing Tasks

The core of this function is to correlate business logic (task execution status) with system resource metrics for root cause analysis.

 Implementation Plan:

a. Data Collection and Correlation

   Source 1: Aquila Trail (Business Status)
       Key Data: `Job ID`, `Task ID`, task status (`Timeout`/`Failed`/`Retried`), task queuing, start/end times, and total task duration.

   Source 2: Cloud Provider Native Monitoring Services (System Metrics)
       AWS CloudWatch / Azure Monitor: Automatically collects detailed system metrics from all EC2 instances (compute nodes):
           CPU Utilization (`CPUUtilization`)
           Memory Utilization (`MemUsedPercent`)
           Disk I/O (`DiskReadBytes`, `DiskWriteBytes`, `EBSReadIOPS`, etc.)
           Network I/O (`NetworkIn`, `NetworkOut`)
       Key Point: Ensure all Aquila compute instances are tagged with a unified resource tag (e.g., `AquilaGrid: XVA-Batch`) for easy filtering.

b. Data Analysis and Correlation Engine

   Trigger Condition: The system periodically scans the Trail, looking for tasks with a status of "Timeout," "Abnormally Long Execution Time" (exceeding the historical average by N standard deviations), or "Failed/Retried."

   Correlation Analysis:
    1.  When a problematic task is identified (e.g., `Job J123`), find the specific compute instances (e.g., `Instance i-abc123`) that executed this task and the task's execution time window (e.g., `14:00 - 15:30`) from the Trail.
    2.  Automatically query CloudWatch to retrieve the time-series data for system metrics (CPU, Memory, Disk I/O, Network I/O) for instance `i-abc123` during that specific time window.

   Bottleneck Identification Logic:
       CPU Bottleneck: CPU utilization consistently exceeds 90% during task execution.
       Memory Bottleneck: Available memory is consistently low, potentially triggering SWAP, leading to increased disk I/O and performance degradation.
       Disk I/O Bottleneck: Disk read/write queue depth is consistently high, or throughput reaches its limit.
       Network Bottleneck: Network throughput reaches the limit for the instance type.
       Resource Competition: Multiple Workers running on the same instance compete for CPU, memory, or network resources.

c. Report Generation and Feedback

   Automated Diagnostic Report Generation: Generate a brief diagnostic report for each identified problematic task.
       Report Content:
           Task ID, User, Status.
           Suspected Bottleneck: e.g., "High CPU utilization causing slow computation."
           Evidence: Provide screenshots or data summaries of key system metrics (e.g., "Average CPU utilization during the task was 98%").
           Optimization Suggestion: e.g., "Consider using Compute Optimized instances (e.g., C-series) instead of Memory Optimized instances (e.g., R-series)."

   User Notification:
       Automatically send this diagnostic report via email to the task submitter.
       In the Trail GUI, on the task's details page, display this report using a prominent warning icon or label (e.g., "Performance Bottleneck") for easy user review and querying.
